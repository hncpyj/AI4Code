{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hncpyj/AI4Code/blob/main/ai4code_codebert_pairwise_score.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0f7cb4a",
      "metadata": {
        "papermill": {
          "duration": 0.052242,
          "end_time": "2022-07-24T07:07:40.745218",
          "exception": false,
          "start_time": "2022-07-24T07:07:40.692976",
          "status": "completed"
        },
        "tags": [],
        "id": "f0f7cb4a"
      },
      "source": [
        "## Thanks @thedevastator for your great [work](https://www.kaggle.com/code/thedevastator/codebert-pairwise)\n",
        "\n",
        "_____\n",
        "**Credits:**<br>\n",
        "This notebook demonstrates a simple ensemble method for ranking problems. It is **based on the two incredible notebooks:**\n",
        "- **[Stronger baseline with code cells](https://www.kaggle.com/code/suicaokhoailang/stronger-baseline-with-code-cells)** by [suicaokhoailang](https://www.kaggle.com/suicaokhoailang)\n",
        "- **[AI4Code Pairwise BertSmall inference](https://www.kaggle.com/code/yuanzhezhou/ai4code-pairwise-bertsmall-inference)** by [yuanzhezhou](https://www.kaggle.com/yuanzhezhou)<br>\n",
        "\n",
        "All credits for the models themselves (both training and prediction) belogs to the original authors! I simply cloned their code and retrained my own version.\n",
        "_____\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Ensembling Rank Based Submissions\n",
        "\n",
        "We are a month away from the finish line and yet there is no high scoring ensemble in sight!\n",
        "\n",
        "Let's fix this. \n",
        "\n",
        "But how do you actually combine rank based predictions? Let alone predictions that come from completly different approaches (direct rank prediction / pairwise).<br>\n",
        "Actually, this is pretty simple: **Average the indices of the elements.**<br>\n",
        "This way, we can sort the final prediction by the ensembled indices and it will simply represent an aggragated representation of the element's location.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0505c78",
      "metadata": {
        "papermill": {
          "duration": 0.051507,
          "end_time": "2022-07-24T07:07:40.851223",
          "exception": false,
          "start_time": "2022-07-24T07:07:40.799716",
          "status": "completed"
        },
        "tags": [],
        "id": "d0505c78"
      },
      "source": [
        "_____\n",
        "\n",
        "### **[Stronger baseline with code cells](https://www.kaggle.com/code/suicaokhoailang/stronger-baseline-with-code-cells)**\n",
        "#### By [suicaokhoailang](https://www.kaggle.com/suicaokhoailang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8e9388d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:07:40.957543Z",
          "iopub.status.busy": "2022-07-24T07:07:40.957134Z",
          "iopub.status.idle": "2022-07-24T07:07:40.972973Z",
          "shell.execute_reply": "2022-07-24T07:07:40.972279Z"
        },
        "papermill": {
          "duration": 0.073793,
          "end_time": "2022-07-24T07:07:40.976706",
          "exception": false,
          "start_time": "2022-07-24T07:07:40.902913",
          "status": "completed"
        },
        "tags": [],
        "id": "e8e9388d"
      },
      "outputs": [],
      "source": [
        "# 노트북 불러오기\n",
        "def read_notebook(path):\n",
        "    import pandas as pd\n",
        "    return (\n",
        "        pd.read_json(\n",
        "            path,\n",
        "            dtype={'cell_type': 'category', 'source': 'str'})\n",
        "        .assign(id=path.stem)\n",
        "        .rename_axis('cell_id')\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "006da82b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:07:41.046626Z",
          "iopub.status.busy": "2022-07-24T07:07:41.046356Z",
          "iopub.status.idle": "2022-07-24T07:07:41.056106Z",
          "shell.execute_reply": "2022-07-24T07:07:41.055459Z"
        },
        "papermill": {
          "duration": 0.04518,
          "end_time": "2022-07-24T07:07:41.057808",
          "exception": false,
          "start_time": "2022-07-24T07:07:41.012628",
          "status": "completed"
        },
        "tags": [],
        "id": "006da82b"
      },
      "outputs": [],
      "source": [
        "# Enter 제거\n",
        "def clean_code(cell): return str(cell).replace(\"\\\\n\", \"\\n\")\n",
        "\n",
        "# 각 셀 당 200번째 글자까지만 가져오기\n",
        "def sample_cells(cells, n):\n",
        "    import numpy as np\n",
        "    cells = [clean_code(cell) for cell in cells]\n",
        "    if n >= len(cells): return [cell[:200] for cell in cells]\n",
        "    else:\n",
        "        results = []\n",
        "        step = len(cells) / n\n",
        "        idx = 0\n",
        "        while int(np.round(idx)) < len(cells):\n",
        "            results.append(cells[int(np.round(idx))])\n",
        "            idx += step        \n",
        "        if cells[-1] not in results: results[-1] = cells[-1]\n",
        "        return results\n",
        "\n",
        "# 마크다운이랑 코드 구분해서 세고 데이터 정리하는거\n",
        "def get_features(df):\n",
        "    from tqdm import tqdm\n",
        "    features = dict()\n",
        "    df = df.sort_values(\"rank\").reset_index(drop=True)\n",
        "    for idx, sub_df in tqdm(df.groupby(\"id\")):\n",
        "        features[idx] = dict()\n",
        "        total_md = sub_df[sub_df.cell_type == \"markdown\"].shape[0]\n",
        "        code_sub_df = sub_df[sub_df.cell_type == \"code\"]\n",
        "        total_code = code_sub_df.shape[0]\n",
        "        codes = sample_cells(code_sub_df.source.values, 20)\n",
        "        features[idx][\"total_code\"] = total_code\n",
        "        features[idx][\"total_md\"] = total_md\n",
        "        features[idx][\"codes\"] = codes\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09b52498",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:07:41.123078Z",
          "iopub.status.busy": "2022-07-24T07:07:41.122825Z",
          "iopub.status.idle": "2022-07-24T07:07:41.154907Z",
          "shell.execute_reply": "2022-07-24T07:07:41.154202Z"
        },
        "papermill": {
          "duration": 0.066635,
          "end_time": "2022-07-24T07:07:41.156607",
          "exception": false,
          "start_time": "2022-07-24T07:07:41.089972",
          "status": "completed"
        },
        "tags": [],
        "id": "09b52498"
      },
      "outputs": [],
      "source": [
        "# 데이터 읽어오기\n",
        "def read_data(data): return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
        "\n",
        "# cpu, gpu 세팅\n",
        "def validate(model, val_loader):    \n",
        "    import sys\n",
        "    import torch    \n",
        "    import numpy as np\n",
        "    from tqdm import tqdm    \n",
        "    model.eval()    \n",
        "    tbar = tqdm(val_loader, file=sys.stdout)    \n",
        "    preds = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for idx, data in enumerate(tbar):\n",
        "            inputs, target = read_data(data)\n",
        "            pred = model(*inputs)\n",
        "            preds.append(pred.detach().cpu().numpy().ravel())\n",
        "            labels.append(target.detach().cpu().numpy().ravel())    \n",
        "    return np.concatenate(labels), np.concatenate(preds)\n",
        "\n",
        "# 예측\n",
        "def predict_caller(args): return predict(args[0], args[1])\n",
        "    \n",
        "# 가비지 컬렉터 임포트 하고 파이토치 불러와서 예측하기\n",
        "def predict(model_path, ckpt_path):\n",
        "    \n",
        "    import gc\n",
        "    import json\n",
        "    import sys, os\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from tqdm import tqdm\n",
        "    from pathlib import Path\n",
        "    from scipy import sparse\n",
        "\n",
        "    data_dir = Path('../input/AI4Code')\n",
        "    paths_test = list((data_dir / 'test').glob('*.json'))\n",
        "    notebooks_test = [\n",
        "        read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n",
        "    ]\n",
        "    test_df = (\n",
        "        pd.concat(notebooks_test)\n",
        "        .set_index('id', append=True)\n",
        "        .swaplevel()\n",
        "        .sort_index(level='id', sort_remaining=False)\n",
        "    ).reset_index()\n",
        "    test_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\n",
        "    test_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
        "\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.nn.functional as F\n",
        "    from torch.utils.data import DataLoader, Dataset\n",
        "    from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "    # 마크다운 모델 프리트레인 시키고\n",
        "    # from_pretrained\n",
        "    # 사전 훈련된 모델 어휘에서 라이브러리의 토크나이저 클래스 중 하나를 인스턴스화한다.\n",
        "    # 인스턴스화할 토크나이저 클래스는 config 개체의 model_type 속성을 기반으로 선택 되거나 누락된 경우\n",
        "    # pretrained_model_name_or_path 문자열 에서 패턴 일치를 사용하는 것으로 대체된다.\n",
        "    class MarkdownModel(nn.Module):\n",
        "        def __init__(self, model_path):\n",
        "            super(MarkdownModel, self).__init__()\n",
        "            self.model = AutoModel.from_pretrained(model_path)\n",
        "            self.top = nn.Linear(769, 1)\n",
        "\n",
        "        def forward(self, ids, mask, fts):\n",
        "            x = self.model(ids, mask)[0]\n",
        "            x = self.top(torch.cat((x[:, 0, :], fts),1))\n",
        "            return x\n",
        "\n",
        "\n",
        "    # 마크다운 데이터셋\n",
        "    class MarkdownDataset(Dataset):\n",
        "\n",
        "        def __init__(self, df, model_name_or_path, total_max_len, md_max_len, fts):\n",
        "            super().__init__()\n",
        "            self.df = df.reset_index(drop=True)\n",
        "            self.md_max_len = md_max_len\n",
        "            self.total_max_len = total_max_len  # maxlen allowed by model config\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "            self.fts = fts\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            row = self.df.iloc[index]\n",
        "\n",
        "            inputs = self.tokenizer.encode_plus(\n",
        "                row.source,\n",
        "                None,\n",
        "                add_special_tokens=True,\n",
        "                max_length=self.md_max_len,\n",
        "                padding=\"max_length\",\n",
        "                return_token_type_ids=True,\n",
        "                truncation=True\n",
        "            )\n",
        "            code_inputs = self.tokenizer.batch_encode_plus(\n",
        "                [str(x) for x in self.fts[row.id][\"codes\"]],\n",
        "                add_special_tokens=True,\n",
        "                max_length=23,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True\n",
        "            )\n",
        "            n_md = self.fts[row.id][\"total_md\"]\n",
        "            n_code = self.fts[row.id][\"total_md\"]\n",
        "            if n_md + n_code == 0:\n",
        "                fts = torch.FloatTensor([0])\n",
        "            else:\n",
        "                fts = torch.FloatTensor([n_md / (n_md + n_code)])\n",
        "\n",
        "            ids = inputs['input_ids']\n",
        "            for x in code_inputs['input_ids']:\n",
        "                ids.extend(x[:-1])\n",
        "            ids = ids[:self.total_max_len]\n",
        "            if len(ids) != self.total_max_len:\n",
        "                ids = ids + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(ids))\n",
        "            ids = torch.LongTensor(ids)\n",
        "\n",
        "            mask = inputs['attention_mask']\n",
        "            for x in code_inputs['attention_mask']:\n",
        "                mask.extend(x[:-1])\n",
        "            mask = mask[:self.total_max_len]\n",
        "            if len(mask) != self.total_max_len:\n",
        "                mask = mask + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(mask))\n",
        "            mask = torch.LongTensor(mask)\n",
        "\n",
        "            assert len(ids) == self.total_max_len\n",
        "\n",
        "            return ids, mask, fts, torch.FloatTensor([row.pct_rank])\n",
        "\n",
        "        def __len__(self):\n",
        "            return self.df.shape[0]\n",
        "    \n",
        "    model = MarkdownModel(model_path)\n",
        "    model = model.cuda()\n",
        "    model.eval()\n",
        "    model.load_state_dict(torch.load(ckpt_path))\n",
        "    BS = 32\n",
        "    NW = 8\n",
        "    MAX_LEN = 64\n",
        "    test_df[\"pct_rank\"] = 0\n",
        "    test_fts = get_features(test_df)\n",
        "    test_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), md_max_len=64,total_max_len=512, model_name_or_path=model_path, fts=test_fts)\n",
        "    test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
        "                              pin_memory=False, drop_last=False)\n",
        "    _, y_test = validate(model, test_loader)\n",
        "    model.to(torch.device('cpu'))\n",
        "    torch.cuda.empty_cache()    \n",
        "    del model, test_loader, test_ds\n",
        "    gc.collect()      \n",
        "    \n",
        "    test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_test\n",
        "    sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
        "    sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
        "    sub_df.head()\n",
        "    sub_df.to_csv(\"submission_1.csv\", index=False)\n",
        "\n",
        "    del test_df, paths_test, notebooks_test, test_fts, model_path, ckpt_path, sub_df\n",
        "    del json, np, pd, tqdm, Path, sparse, torch, sys, os, nn, F, AutoModel, AutoTokenizer\n",
        "    gc.collect()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a368ba18",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:07:41.222308Z",
          "iopub.status.busy": "2022-07-24T07:07:41.222049Z",
          "iopub.status.idle": "2022-07-24T07:08:09.027485Z",
          "shell.execute_reply": "2022-07-24T07:08:09.026800Z"
        },
        "papermill": {
          "duration": 27.839923,
          "end_time": "2022-07-24T07:08:09.029422",
          "exception": false,
          "start_time": "2022-07-24T07:07:41.189499",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "f77953f7408a4e83b2a0e8b097495b3a"
          ]
        },
        "id": "a368ba18",
        "outputId": "aa486da2-74a5-4a64-cbd8-47a185308a6d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f77953f7408a4e83b2a0e8b097495b3a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test NBs: 100%|██████████| 4/4 [00:00<00:00, 20.58it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 740.49it/s]\n",
            "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:02<00:00,  1.18s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "ckpt_path = \"../input/ai4code-model/model.bin\"\n",
        "model_path = \"../input/codebert-base/codebert-base/\"\n",
        "\n",
        "from tqdm.contrib.concurrent import process_map\n",
        "process_map(predict_caller, [(model_path, ckpt_path)])[0]\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42d2476d",
      "metadata": {
        "papermill": {
          "duration": 0.040804,
          "end_time": "2022-07-24T07:08:09.110480",
          "exception": false,
          "start_time": "2022-07-24T07:08:09.069676",
          "status": "completed"
        },
        "tags": [],
        "id": "42d2476d"
      },
      "source": [
        "_____\n",
        "\n",
        "### **[AI4Code Pairwise BertSmall inference](https://www.kaggle.com/code/yuanzhezhou/ai4code-pairwise-bertsmall-inference)**\n",
        "#### By [yuanzhezhou](https://www.kaggle.com/yuanzhezhou)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17b98eb0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:09.189199Z",
          "iopub.status.busy": "2022-07-24T07:08:09.188950Z",
          "iopub.status.idle": "2022-07-24T07:08:15.430475Z",
          "shell.execute_reply": "2022-07-24T07:08:15.429453Z"
        },
        "papermill": {
          "duration": 6.282087,
          "end_time": "2022-07-24T07:08:15.433175",
          "exception": false,
          "start_time": "2022-07-24T07:08:09.151088",
          "status": "completed"
        },
        "tags": [],
        "id": "17b98eb0",
        "outputId": "8b8a24a6-0432-484b-d6ea-d0329019b4e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train NBs: 100%|██████████| 200/200 [00:01<00:00, 102.55it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>cell_type</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th>cell_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">00644e80ec8e70</th>\n",
              "      <th>2d19bafd</th>\n",
              "      <td>code</td>\n",
              "      <td># This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>804ac9dd</th>\n",
              "      <td>code</td>\n",
              "      <td>import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nsns.set_style('whit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>e3290b2e</th>\n",
              "      <td>code</td>\n",
              "      <td>df = pd.read_csv('../input/montcoalert/911.csv')\\ndf.head()</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40a2cdc4</th>\n",
              "      <td>code</td>\n",
              "      <td>df.info()</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28c27206</th>\n",
              "      <td>code</td>\n",
              "      <td>df['zip'].value_counts().head()</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">fd3bbdf3840149</th>\n",
              "      <th>3727a048</th>\n",
              "      <td>markdown</td>\n",
              "      <td>There is 1 csv file in the current version of the dataset:\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1400526</th>\n",
              "      <td>markdown</td>\n",
              "      <td>Let's take a quick look at what the data looks like:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>916b863e</th>\n",
              "      <td>markdown</td>\n",
              "      <td>## Introduction\\r\\nGreetings from the Kaggle bot! This is an automatically-generated kernel with starter code demons...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eb475d5d</th>\n",
              "      <td>markdown</td>\n",
              "      <td>## Conclusion\\r\\nThis concludes your starter analysis! To go forward from here, click the blue \"Edit Notebook\" butto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4bebc8b8</th>\n",
              "      <td>markdown</td>\n",
              "      <td>## Exploratory Analysis\\r\\nTo begin this exploratory analysis, first use `matplotlib` to import libraries and define...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8735 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        cell_type                                                                                                                   source\n",
              "id             cell_id                                                                                                                                    \n",
              "00644e80ec8e70 2d19bafd      code  # This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...\n",
              "               804ac9dd      code  import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nsns.set_style('whit...\n",
              "               e3290b2e      code                                                              df = pd.read_csv('../input/montcoalert/911.csv')\\ndf.head()\n",
              "               40a2cdc4      code                                                                                                                df.info()\n",
              "               28c27206      code                                                                                          df['zip'].value_counts().head()\n",
              "...                           ...                                                                                                                      ...\n",
              "fd3bbdf3840149 3727a048  markdown                                                             There is 1 csv file in the current version of the dataset:\\n\n",
              "               f1400526  markdown                                                                     Let's take a quick look at what the data looks like:\n",
              "               916b863e  markdown  ## Introduction\\r\\nGreetings from the Kaggle bot! This is an automatically-generated kernel with starter code demons...\n",
              "               eb475d5d  markdown  ## Conclusion\\r\\nThis concludes your starter analysis! To go forward from here, click the blue \"Edit Notebook\" butto...\n",
              "               4bebc8b8  markdown  ## Exploratory Analysis\\r\\nTo begin this exploratory analysis, first use `matplotlib` to import libraries and define...\n",
              "\n",
              "[8735 rows x 2 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from scipy import sparse\n",
        "\n",
        "pd.options.display.width = 180\n",
        "pd.options.display.max_colwidth = 120\n",
        "\n",
        "BERT_PATH = \"../input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased\"\n",
        "\n",
        "data_dir = Path('../input/AI4Code')\n",
        "NUM_TRAIN = 200\n",
        "\n",
        "def read_notebook(path):\n",
        "    return (\n",
        "        pd.read_json(\n",
        "            path,\n",
        "            dtype={'cell_type': 'category', 'source': 'str'})\n",
        "        .assign(id=path.stem)\n",
        "        .rename_axis('cell_id')\n",
        "    )\n",
        "\n",
        "paths_train = list((data_dir / 'train').glob('*.json'))[:NUM_TRAIN]\n",
        "notebooks_train = [\n",
        "    read_notebook(path) for path in tqdm(paths_train, desc='Train NBs')\n",
        "]\n",
        "df = (\n",
        "    pd.concat(notebooks_train)\n",
        "    .set_index('id', append=True)\n",
        "    .swaplevel()\n",
        "    .sort_index(level='id', sort_remaining=False)\n",
        ")\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4425af8f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:15.526994Z",
          "iopub.status.busy": "2022-07-24T07:08:15.526741Z",
          "iopub.status.idle": "2022-07-24T07:08:15.543488Z",
          "shell.execute_reply": "2022-07-24T07:08:15.542433Z"
        },
        "papermill": {
          "duration": 0.064872,
          "end_time": "2022-07-24T07:08:15.546663",
          "exception": false,
          "start_time": "2022-07-24T07:08:15.481791",
          "status": "completed"
        },
        "tags": [],
        "id": "4425af8f",
        "outputId": "f5d17923-8b4b-45e1-82d2-52404df6f0dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Notebook: 051d049a469e47\n",
            "The disordered notebook:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cell_type</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cell_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d7e4aeec</th>\n",
              "      <td>code</td>\n",
              "      <td>!pip install pyspark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aeb2a838</th>\n",
              "      <td>code</td>\n",
              "      <td>from pyspark.sql import SparkSession\\nspark = SparkSession.builder.appName('classification').getOrCreate()</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12c1a908</th>\n",
              "      <td>code</td>\n",
              "      <td>from itertools import chain\\nfrom pyspark.sql.functions import count, mean, when, lit, create_map, regexp_extract</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>e7e68995</th>\n",
              "      <td>code</td>\n",
              "      <td>df1 = spark.read.csv('../input/titanic/train.csv',\\\\n                     header=True, inferSchema=True)\\ndf2 = spar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320bedc7</th>\n",
              "      <td>code</td>\n",
              "      <td>df1.printSchema()</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61a146d1</th>\n",
              "      <td>markdown</td>\n",
              "      <td>This is the in-sample accuracy which is generally higher than the out-sample accuracy.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0d7a91e3</th>\n",
              "      <td>markdown</td>\n",
              "      <td>The basic idea for age imputation is to take the title of the people from the name column and impute with the averag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c0b25242</th>\n",
              "      <td>markdown</td>\n",
              "      <td># Introduction \\n\\nSpark is a hot topic on big data analytics. Spark is an analytics engine for big data processing....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1b7707e6</th>\n",
              "      <td>markdown</td>\n",
              "      <td>The output of the show() might look ugly, especially if there are a large number of columns in the dataframe. At thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503a84f0</th>\n",
              "      <td>markdown</td>\n",
              "      <td>### Pipeline \\n\\nAt this stage, it is worth introducing pipeline. In machine learning, it is common to run a sequenc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>91 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         cell_type                                                                                                                   source\n",
              "cell_id                                                                                                                                    \n",
              "d7e4aeec      code                                                                                                     !pip install pyspark\n",
              "aeb2a838      code               from pyspark.sql import SparkSession\\nspark = SparkSession.builder.appName('classification').getOrCreate()\n",
              "12c1a908      code        from itertools import chain\\nfrom pyspark.sql.functions import count, mean, when, lit, create_map, regexp_extract\n",
              "e7e68995      code  df1 = spark.read.csv('../input/titanic/train.csv',\\\\n                     header=True, inferSchema=True)\\ndf2 = spar...\n",
              "320bedc7      code                                                                                                        df1.printSchema()\n",
              "...            ...                                                                                                                      ...\n",
              "61a146d1  markdown                                  This is the in-sample accuracy which is generally higher than the out-sample accuracy. \n",
              "0d7a91e3  markdown  The basic idea for age imputation is to take the title of the people from the name column and impute with the averag...\n",
              "c0b25242  markdown  # Introduction \\n\\nSpark is a hot topic on big data analytics. Spark is an analytics engine for big data processing....\n",
              "1b7707e6  markdown  The output of the show() might look ugly, especially if there are a large number of columns in the dataframe. At thi...\n",
              "503a84f0  markdown  ### Pipeline \\n\\nAt this stage, it is worth introducing pipeline. In machine learning, it is common to run a sequenc...\n",
              "\n",
              "[91 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Get an example notebook\n",
        "nb_id = df.index.unique('id')[6]\n",
        "print('Notebook:', nb_id)\n",
        "\n",
        "print(\"The disordered notebook:\")\n",
        "nb = df.loc[nb_id, :]\n",
        "display(nb)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "826d8a12",
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:15.637882Z",
          "iopub.status.busy": "2022-07-24T07:08:15.637642Z",
          "iopub.status.idle": "2022-07-24T07:08:18.272959Z",
          "shell.execute_reply": "2022-07-24T07:08:18.272250Z"
        },
        "papermill": {
          "duration": 2.682802,
          "end_time": "2022-07-24T07:08:18.274690",
          "exception": false,
          "start_time": "2022-07-24T07:08:15.591888",
          "status": "completed"
        },
        "tags": [],
        "id": "826d8a12",
        "outputId": "7cc3104d-5b52-4291-e05f-b473d38f4429"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id\n",
              "00001756c60be8    [1862f0a6, 448eb224, 2a9e43d6, 7e2f170a, 038b763d, 77e56113, 2eefe0ef, 1ae087ab, 0beab1cd, 8ffe0b25, 9a78ab76, 0d136...\n",
              "00015c83e2717b    [2e94bd7a, 3e99dee9, b5e286ea, da4f7550, c417225b, 51e3cd89, 2600b4eb, 75b65993, cf195f8b, 25699d02, 72b3201a, f2c75...\n",
              "0001bdd4021779    [3fdc37be, 073782ca, 8ea7263c, 80543cd8, 38310c80, 073e27e5, 015d52a4, ad7679ef, 7fde4f04, 07c52510, 0a1a7a39, 0bcd3...\n",
              "0001daf4c2c76d    [97266564, a898e555, 86605076, 76cc2642, ef279279, df6c939f, 2476da96, 00f87d0a, ae93e8e6, 58aadb1d, d20b0094, 986fd...\n",
              "0002115f48f982                                 [9ec225f0, 18281c6c, e3b6b115, 4a044c54, 365fe576, a3188e54, b3f6e12d, ee7655ca, 84125b7a]\n",
              "                                                                           ...                                                           \n",
              "fffc30d5a0bc46    [09727c0c, ff1ea6a0, ddfef603, a01ce9b3, 3ba953ee, bf92a015, f4a0492a, 095812e6, 53125cfe, aa32a700, 63340e73, 06d8c...\n",
              "fffc3b44869198    [978a5137, faa48f03, 28dfb12a, eea2e812, 64fef97c, 4e0d1510, 58e68f2c, 8784e700, 4bd5a4cf, dc14bfec, 2aff7603, 8047d...\n",
              "fffc63ff750064    [5015c300, 411b85d9, 8238198c, f4781d1d, b5532930, e1f223e5, e7e67119, 4aaf741d, 7229cce6, a7fa3628, e4c2fa86, 1f8f9...\n",
              "fffcd063cda949    [7e6266ad, d8281fc5, d4ffcaef, 3e0e4a47, 21387fc8, cc229f9a, baed9c8b, d1bb21aa, 82979992, 65f95dad, eba4fa9e, c97e2...\n",
              "fffe1d764579d5    [1a63248d, 9c3b96a5, 1398a873, 4e2d4c2d, f71c538e, 8b44a5e8, 385dff7a, b8254ef8, 4d0e433e, debc496c, e15ae953, e4d79...\n",
              "Name: cell_order, Length: 139256, dtype: object"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "df_orders = pd.read_csv(\n",
        "    data_dir / 'train_orders.csv',\n",
        "    index_col='id',\n",
        "    squeeze=True,\n",
        ").str.split()  # Split the string representation of cell_ids into a list\n",
        "\n",
        "df_orders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a60513b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:18.366458Z",
          "iopub.status.busy": "2022-07-24T07:08:18.366194Z",
          "iopub.status.idle": "2022-07-24T07:08:18.373616Z",
          "shell.execute_reply": "2022-07-24T07:08:18.372847Z"
        },
        "papermill": {
          "duration": 0.056787,
          "end_time": "2022-07-24T07:08:18.376256",
          "exception": false,
          "start_time": "2022-07-24T07:08:18.319469",
          "status": "completed"
        },
        "tags": [],
        "id": "5a60513b",
        "outputId": "de8c04a2-b719-49ca-f3d8-b3af895ad007"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "73"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_orders.loc[\"002ba502bdac45\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0be2518a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:18.469119Z",
          "iopub.status.busy": "2022-07-24T07:08:18.468452Z",
          "iopub.status.idle": "2022-07-24T07:08:18.481208Z",
          "shell.execute_reply": "2022-07-24T07:08:18.480374Z"
        },
        "papermill": {
          "duration": 0.062599,
          "end_time": "2022-07-24T07:08:18.484285",
          "exception": false,
          "start_time": "2022-07-24T07:08:18.421686",
          "status": "completed"
        },
        "tags": [],
        "id": "0be2518a",
        "outputId": "1f6fc9aa-734c-4de0-b43b-14f4e507ae85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The ordered notebook:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cell_type</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cell_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>c0b25242</th>\n",
              "      <td>markdown</td>\n",
              "      <td># Introduction \\n\\nSpark is a hot topic on big data analytics. Spark is an analytics engine for big data processing....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d7e4aeec</th>\n",
              "      <td>code</td>\n",
              "      <td>!pip install pyspark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cd6b2dda</th>\n",
              "      <td>markdown</td>\n",
              "      <td>First, we need to start a SparkSession and create a spark instance.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aeb2a838</th>\n",
              "      <td>code</td>\n",
              "      <td>from pyspark.sql import SparkSession\\nspark = SparkSession.builder.appName('classification').getOrCreate()</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12c1a908</th>\n",
              "      <td>code</td>\n",
              "      <td>from itertools import chain\\nfrom pyspark.sql.functions import count, mean, when, lit, create_map, regexp_extract</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3563f858</th>\n",
              "      <td>code</td>\n",
              "      <td># Inspecting csv file in pandas \\nimport pandas as pd\\npd.read_csv('submission.csv').head()</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611ae31</th>\n",
              "      <td>markdown</td>\n",
              "      <td>We can also save the model itself for future use so that you don't have to train every time.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cd0d933d</th>\n",
              "      <td>code</td>\n",
              "      <td>model_final.write().save('titanic_classification.model')</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d943cd36</th>\n",
              "      <td>code</td>\n",
              "      <td>! ls titanic_classification.model/*</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66c450ba</th>\n",
              "      <td>markdown</td>\n",
              "      <td># Final thought. \\n\\n- We just presented a base model here and established that Spark is basically capable of doing ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>91 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         cell_type                                                                                                                   source\n",
              "cell_id                                                                                                                                    \n",
              "c0b25242  markdown  # Introduction \\n\\nSpark is a hot topic on big data analytics. Spark is an analytics engine for big data processing....\n",
              "d7e4aeec      code                                                                                                     !pip install pyspark\n",
              "cd6b2dda  markdown                                                      First, we need to start a SparkSession and create a spark instance.\n",
              "aeb2a838      code               from pyspark.sql import SparkSession\\nspark = SparkSession.builder.appName('classification').getOrCreate()\n",
              "12c1a908      code        from itertools import chain\\nfrom pyspark.sql.functions import count, mean, when, lit, create_map, regexp_extract\n",
              "...            ...                                                                                                                      ...\n",
              "3563f858      code                              # Inspecting csv file in pandas \\nimport pandas as pd\\npd.read_csv('submission.csv').head()\n",
              "7611ae31  markdown                           We can also save the model itself for future use so that you don't have to train every time.  \n",
              "cd0d933d      code                                                                 model_final.write().save('titanic_classification.model')\n",
              "d943cd36      code                                                                                      ! ls titanic_classification.model/*\n",
              "66c450ba  markdown  # Final thought. \\n\\n- We just presented a base model here and established that Spark is basically capable of doing ...\n",
              "\n",
              "[91 rows x 2 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cell_order = df_orders.loc[nb_id]\n",
        "\n",
        "print(\"The ordered notebook:\")\n",
        "nb.loc[cell_order, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8fb60bd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:18.577248Z",
          "iopub.status.busy": "2022-07-24T07:08:18.577007Z",
          "iopub.status.idle": "2022-07-24T07:08:18.590892Z",
          "shell.execute_reply": "2022-07-24T07:08:18.590211Z"
        },
        "papermill": {
          "duration": 0.062559,
          "end_time": "2022-07-24T07:08:18.592760",
          "exception": false,
          "start_time": "2022-07-24T07:08:18.530201",
          "status": "completed"
        },
        "tags": [],
        "id": "b8fb60bd",
        "outputId": "d082f3c8-adb2-4111-c671-8664e63d7738"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rank</th>\n",
              "      <th>cell_type</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cell_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d7e4aeec</th>\n",
              "      <td>1</td>\n",
              "      <td>code</td>\n",
              "      <td>!pip install pyspark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aeb2a838</th>\n",
              "      <td>3</td>\n",
              "      <td>code</td>\n",
              "      <td>from pyspark.sql import SparkSession\\nspark = SparkSession.builder.appName('classification').getOrCreate()</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12c1a908</th>\n",
              "      <td>4</td>\n",
              "      <td>code</td>\n",
              "      <td>from itertools import chain\\nfrom pyspark.sql.functions import count, mean, when, lit, create_map, regexp_extract</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>e7e68995</th>\n",
              "      <td>6</td>\n",
              "      <td>code</td>\n",
              "      <td>df1 = spark.read.csv('../input/titanic/train.csv',\\\\n                     header=True, inferSchema=True)\\ndf2 = spar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320bedc7</th>\n",
              "      <td>8</td>\n",
              "      <td>code</td>\n",
              "      <td>df1.printSchema()</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61a146d1</th>\n",
              "      <td>80</td>\n",
              "      <td>markdown</td>\n",
              "      <td>This is the in-sample accuracy which is generally higher than the out-sample accuracy.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0d7a91e3</th>\n",
              "      <td>37</td>\n",
              "      <td>markdown</td>\n",
              "      <td>The basic idea for age imputation is to take the title of the people from the name column and impute with the averag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c0b25242</th>\n",
              "      <td>0</td>\n",
              "      <td>markdown</td>\n",
              "      <td># Introduction \\n\\nSpark is a hot topic on big data analytics. Spark is an analytics engine for big data processing....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1b7707e6</th>\n",
              "      <td>11</td>\n",
              "      <td>markdown</td>\n",
              "      <td>The output of the show() might look ugly, especially if there are a large number of columns in the dataframe. At thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503a84f0</th>\n",
              "      <td>78</td>\n",
              "      <td>markdown</td>\n",
              "      <td>### Pipeline \\n\\nAt this stage, it is worth introducing pipeline. In machine learning, it is common to run a sequenc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>91 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          rank cell_type                                                                                                                   source\n",
              "cell_id                                                                                                                                          \n",
              "d7e4aeec     1      code                                                                                                     !pip install pyspark\n",
              "aeb2a838     3      code               from pyspark.sql import SparkSession\\nspark = SparkSession.builder.appName('classification').getOrCreate()\n",
              "12c1a908     4      code        from itertools import chain\\nfrom pyspark.sql.functions import count, mean, when, lit, create_map, regexp_extract\n",
              "e7e68995     6      code  df1 = spark.read.csv('../input/titanic/train.csv',\\\\n                     header=True, inferSchema=True)\\ndf2 = spar...\n",
              "320bedc7     8      code                                                                                                        df1.printSchema()\n",
              "...        ...       ...                                                                                                                      ...\n",
              "61a146d1    80  markdown                                  This is the in-sample accuracy which is generally higher than the out-sample accuracy. \n",
              "0d7a91e3    37  markdown  The basic idea for age imputation is to take the title of the people from the name column and impute with the averag...\n",
              "c0b25242     0  markdown  # Introduction \\n\\nSpark is a hot topic on big data analytics. Spark is an analytics engine for big data processing....\n",
              "1b7707e6    11  markdown  The output of the show() might look ugly, especially if there are a large number of columns in the dataframe. At thi...\n",
              "503a84f0    78  markdown  ### Pipeline \\n\\nAt this stage, it is worth introducing pipeline. In machine learning, it is common to run a sequenc...\n",
              "\n",
              "[91 rows x 3 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_ranks(base, derived):\n",
        "    return [base.index(d) for d in derived]\n",
        "\n",
        "cell_ranks = get_ranks(cell_order, list(nb.index))\n",
        "nb.insert(0, 'rank', cell_ranks)\n",
        "\n",
        "nb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e805b4d9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:18.687676Z",
          "iopub.status.busy": "2022-07-24T07:08:18.686964Z",
          "iopub.status.idle": "2022-07-24T07:08:18.773217Z",
          "shell.execute_reply": "2022-07-24T07:08:18.772265Z"
        },
        "papermill": {
          "duration": 0.136737,
          "end_time": "2022-07-24T07:08:18.775823",
          "exception": false,
          "start_time": "2022-07-24T07:08:18.639086",
          "status": "completed"
        },
        "tags": [],
        "id": "e805b4d9",
        "outputId": "319416d3-d043-46cc-8305-5096db965563"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th>cell_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">00644e80ec8e70</th>\n",
              "      <th>2d19bafd</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>804ac9dd</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>e3290b2e</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40a2cdc4</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28c27206</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">fd3bbdf3840149</th>\n",
              "      <th>3727a048</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1400526</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>916b863e</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eb475d5d</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4bebc8b8</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8735 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        rank\n",
              "id             cell_id      \n",
              "00644e80ec8e70 2d19bafd    0\n",
              "               804ac9dd    1\n",
              "               e3290b2e    2\n",
              "               40a2cdc4    3\n",
              "               28c27206    5\n",
              "...                      ...\n",
              "fd3bbdf3840149 3727a048    3\n",
              "               f1400526   12\n",
              "               916b863e    0\n",
              "               eb475d5d   16\n",
              "               4bebc8b8    1\n",
              "\n",
              "[8735 rows x 1 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_orders_ = df_orders.to_frame().join(\n",
        "    df.reset_index('cell_id').groupby('id')['cell_id'].apply(list),\n",
        "    how='right',\n",
        ")\n",
        "\n",
        "ranks = {}\n",
        "for id_, cell_order, cell_id in df_orders_.itertuples():\n",
        "    ranks[id_] = {'cell_id': cell_id, 'rank': get_ranks(cell_order, cell_id)}\n",
        "\n",
        "df_ranks = (\n",
        "    pd.DataFrame\n",
        "    .from_dict(ranks, orient='index')\n",
        "    .rename_axis('id')\n",
        "    .apply(pd.Series.explode)\n",
        "    .set_index('cell_id', append=True)\n",
        ")\n",
        "\n",
        "df_ranks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "304d6315",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:18.875107Z",
          "iopub.status.busy": "2022-07-24T07:08:18.874854Z",
          "iopub.status.idle": "2022-07-24T07:08:19.089767Z",
          "shell.execute_reply": "2022-07-24T07:08:19.089108Z"
        },
        "papermill": {
          "duration": 0.266956,
          "end_time": "2022-07-24T07:08:19.091559",
          "exception": false,
          "start_time": "2022-07-24T07:08:18.824603",
          "status": "completed"
        },
        "tags": [],
        "id": "304d6315",
        "outputId": "c1cc6f5b-ff86-42ac-f1b6-4ef1b31e49a1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ancestor_id</th>\n",
              "      <th>parent_id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>00001756c60be8</th>\n",
              "      <td>945aea18</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00015c83e2717b</th>\n",
              "      <td>aa2da37e</td>\n",
              "      <td>317b65d12af9df</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0001bdd4021779</th>\n",
              "      <td>a7711fde</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0001daf4c2c76d</th>\n",
              "      <td>090152ca</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0002115f48f982</th>\n",
              "      <td>272b483a</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fffc30d5a0bc46</th>\n",
              "      <td>6aed207b</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fffc3b44869198</th>\n",
              "      <td>a6aaa8d7</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fffc63ff750064</th>\n",
              "      <td>0a1b5b65</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fffcd063cda949</th>\n",
              "      <td>d971e960</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fffe1d764579d5</th>\n",
              "      <td>3c40bfa6</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>139256 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               ancestor_id       parent_id\n",
              "id                                        \n",
              "00001756c60be8    945aea18             NaN\n",
              "00015c83e2717b    aa2da37e  317b65d12af9df\n",
              "0001bdd4021779    a7711fde             NaN\n",
              "0001daf4c2c76d    090152ca             NaN\n",
              "0002115f48f982    272b483a             NaN\n",
              "...                    ...             ...\n",
              "fffc30d5a0bc46    6aed207b             NaN\n",
              "fffc3b44869198    a6aaa8d7             NaN\n",
              "fffc63ff750064    0a1b5b65             NaN\n",
              "fffcd063cda949    d971e960             NaN\n",
              "fffe1d764579d5    3c40bfa6             NaN\n",
              "\n",
              "[139256 rows x 2 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_ancestors = pd.read_csv(data_dir / 'train_ancestors.csv', index_col='id')\n",
        "df_ancestors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95558591",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:19.190953Z",
          "iopub.status.busy": "2022-07-24T07:08:19.190693Z",
          "iopub.status.idle": "2022-07-24T07:08:19.258937Z",
          "shell.execute_reply": "2022-07-24T07:08:19.258251Z"
        },
        "papermill": {
          "duration": 0.11932,
          "end_time": "2022-07-24T07:08:19.260762",
          "exception": false,
          "start_time": "2022-07-24T07:08:19.141442",
          "status": "completed"
        },
        "tags": [],
        "id": "95558591",
        "outputId": "2306bf23-1123-4c07-9a4a-88b5738e17ad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cell_id</th>\n",
              "      <th>cell_type</th>\n",
              "      <th>source</th>\n",
              "      <th>rank</th>\n",
              "      <th>ancestor_id</th>\n",
              "      <th>parent_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00644e80ec8e70</td>\n",
              "      <td>2d19bafd</td>\n",
              "      <td>code</td>\n",
              "      <td># This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...</td>\n",
              "      <td>0</td>\n",
              "      <td>dc83319e</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00644e80ec8e70</td>\n",
              "      <td>804ac9dd</td>\n",
              "      <td>code</td>\n",
              "      <td>import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nsns.set_style('whit...</td>\n",
              "      <td>1</td>\n",
              "      <td>dc83319e</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00644e80ec8e70</td>\n",
              "      <td>e3290b2e</td>\n",
              "      <td>code</td>\n",
              "      <td>df = pd.read_csv('../input/montcoalert/911.csv')\\ndf.head()</td>\n",
              "      <td>2</td>\n",
              "      <td>dc83319e</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00644e80ec8e70</td>\n",
              "      <td>40a2cdc4</td>\n",
              "      <td>code</td>\n",
              "      <td>df.info()</td>\n",
              "      <td>3</td>\n",
              "      <td>dc83319e</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00644e80ec8e70</td>\n",
              "      <td>28c27206</td>\n",
              "      <td>code</td>\n",
              "      <td>df['zip'].value_counts().head()</td>\n",
              "      <td>5</td>\n",
              "      <td>dc83319e</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8730</th>\n",
              "      <td>fd3bbdf3840149</td>\n",
              "      <td>3727a048</td>\n",
              "      <td>markdown</td>\n",
              "      <td>There is 1 csv file in the current version of the dataset:\\n</td>\n",
              "      <td>3</td>\n",
              "      <td>a4b2c4d9</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8731</th>\n",
              "      <td>fd3bbdf3840149</td>\n",
              "      <td>f1400526</td>\n",
              "      <td>markdown</td>\n",
              "      <td>Let's take a quick look at what the data looks like:</td>\n",
              "      <td>12</td>\n",
              "      <td>a4b2c4d9</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8732</th>\n",
              "      <td>fd3bbdf3840149</td>\n",
              "      <td>916b863e</td>\n",
              "      <td>markdown</td>\n",
              "      <td>## Introduction\\r\\nGreetings from the Kaggle bot! This is an automatically-generated kernel with starter code demons...</td>\n",
              "      <td>0</td>\n",
              "      <td>a4b2c4d9</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8733</th>\n",
              "      <td>fd3bbdf3840149</td>\n",
              "      <td>eb475d5d</td>\n",
              "      <td>markdown</td>\n",
              "      <td>## Conclusion\\r\\nThis concludes your starter analysis! To go forward from here, click the blue \"Edit Notebook\" butto...</td>\n",
              "      <td>16</td>\n",
              "      <td>a4b2c4d9</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8734</th>\n",
              "      <td>fd3bbdf3840149</td>\n",
              "      <td>4bebc8b8</td>\n",
              "      <td>markdown</td>\n",
              "      <td>## Exploratory Analysis\\r\\nTo begin this exploratory analysis, first use `matplotlib` to import libraries and define...</td>\n",
              "      <td>1</td>\n",
              "      <td>a4b2c4d9</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8735 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id   cell_id cell_type                                                                                                                   source rank  \\\n",
              "0     00644e80ec8e70  2d19bafd      code  # This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...    0   \n",
              "1     00644e80ec8e70  804ac9dd      code  import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nsns.set_style('whit...    1   \n",
              "2     00644e80ec8e70  e3290b2e      code                                                              df = pd.read_csv('../input/montcoalert/911.csv')\\ndf.head()    2   \n",
              "3     00644e80ec8e70  40a2cdc4      code                                                                                                                df.info()    3   \n",
              "4     00644e80ec8e70  28c27206      code                                                                                          df['zip'].value_counts().head()    5   \n",
              "...              ...       ...       ...                                                                                                                      ...  ...   \n",
              "8730  fd3bbdf3840149  3727a048  markdown                                                             There is 1 csv file in the current version of the dataset:\\n    3   \n",
              "8731  fd3bbdf3840149  f1400526  markdown                                                                     Let's take a quick look at what the data looks like:   12   \n",
              "8732  fd3bbdf3840149  916b863e  markdown  ## Introduction\\r\\nGreetings from the Kaggle bot! This is an automatically-generated kernel with starter code demons...    0   \n",
              "8733  fd3bbdf3840149  eb475d5d  markdown  ## Conclusion\\r\\nThis concludes your starter analysis! To go forward from here, click the blue \"Edit Notebook\" butto...   16   \n",
              "8734  fd3bbdf3840149  4bebc8b8  markdown  ## Exploratory Analysis\\r\\nTo begin this exploratory analysis, first use `matplotlib` to import libraries and define...    1   \n",
              "\n",
              "     ancestor_id parent_id  \n",
              "0       dc83319e       NaN  \n",
              "1       dc83319e       NaN  \n",
              "2       dc83319e       NaN  \n",
              "3       dc83319e       NaN  \n",
              "4       dc83319e       NaN  \n",
              "...          ...       ...  \n",
              "8730    a4b2c4d9       NaN  \n",
              "8731    a4b2c4d9       NaN  \n",
              "8732    a4b2c4d9       NaN  \n",
              "8733    a4b2c4d9       NaN  \n",
              "8734    a4b2c4d9       NaN  \n",
              "\n",
              "[8735 rows x 7 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.reset_index().merge(df_ranks, on=[\"id\", \"cell_id\"]).merge(df_ancestors, on=[\"id\"])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a0a2552",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:19.359084Z",
          "iopub.status.busy": "2022-07-24T07:08:19.358496Z",
          "iopub.status.idle": "2022-07-24T07:08:19.581016Z",
          "shell.execute_reply": "2022-07-24T07:08:19.580238Z"
        },
        "papermill": {
          "duration": 0.274043,
          "end_time": "2022-07-24T07:08:19.583193",
          "exception": false,
          "start_time": "2022-07-24T07:08:19.309150",
          "status": "completed"
        },
        "tags": [],
        "id": "3a0a2552",
        "outputId": "10792f41-6a14-4ec7-d38c-d8cd2952c28d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df[\"pct_rank\"] = df[\"rank\"] / df.groupby(\"id\")[\"cell_id\"].transform(\"count\")\n",
        "df[\"pct_rank\"].hist(bins=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1172dc80",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:19.684311Z",
          "iopub.status.busy": "2022-07-24T07:08:19.683571Z",
          "iopub.status.idle": "2022-07-24T07:08:44.839478Z",
          "shell.execute_reply": "2022-07-24T07:08:44.838738Z"
        },
        "papermill": {
          "duration": 25.209139,
          "end_time": "2022-07-24T07:08:44.841712",
          "exception": false,
          "start_time": "2022-07-24T07:08:19.632573",
          "status": "completed"
        },
        "tags": [],
        "id": "1172dc80",
        "outputId": "1bd2a5fb-fcc2-48cd-ca0b-207a4fcf51b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading wordnet: <urlopen error [Errno -3] Temporary\n",
            "[nltk_data]     failure in name resolution>\n"
          ]
        }
      ],
      "source": [
        "dict_cellid_source = dict(zip(df['cell_id'].values, df['source'].values))\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk; nltk.download('wordnet')\n",
        "\n",
        "stemmer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(document):\n",
        "        # Remove all the special characters\n",
        "        document = re.sub(r'\\W', ' ', str(document))\n",
        "\n",
        "        # remove all single characters\n",
        "        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
        "\n",
        "        # Remove single characters from the start\n",
        "        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n",
        "\n",
        "        # Substituting multiple spaces with single space\n",
        "        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "\n",
        "        # Removing prefixed 'b'\n",
        "        document = re.sub(r'^b\\s+', '', document)\n",
        "\n",
        "        # Converting to Lowercase\n",
        "        document = document.lower()\n",
        "        #return document\n",
        "\n",
        "        # Lemmatization\n",
        "        tokens = document.split()\n",
        "        tokens = [stemmer.lemmatize(word) for word in tokens]\n",
        "        tokens = [word for word in tokens if len(word) > 3]\n",
        "\n",
        "        preprocessed_text = ' '.join(tokens)\n",
        "        return preprocessed_text\n",
        "\n",
        "    \n",
        "def preprocess_df(df):\n",
        "    \"\"\"\n",
        "    This function is for processing sorce of notebook\n",
        "    returns preprocessed dataframe\n",
        "    \"\"\"\n",
        "    return [preprocess_text(message) for message in df.source]\n",
        "\n",
        "df.source = df.source.apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39774342",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:44.945535Z",
          "iopub.status.busy": "2022-07-24T07:08:44.944933Z",
          "iopub.status.idle": "2022-07-24T07:08:44.965372Z",
          "shell.execute_reply": "2022-07-24T07:08:44.964690Z"
        },
        "papermill": {
          "duration": 0.074857,
          "end_time": "2022-07-24T07:08:44.967176",
          "exception": false,
          "start_time": "2022-07-24T07:08:44.892319",
          "status": "completed"
        },
        "tags": [],
        "id": "39774342"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "NVALID = 0.1  # size of validation set\n",
        "\n",
        "splitter = GroupShuffleSplit(n_splits=1, test_size=NVALID, random_state=0)\n",
        "\n",
        "train_ind, val_ind = next(splitter.split(df, groups=df[\"ancestor_id\"]))\n",
        "\n",
        "train_df = df.loc[train_ind].reset_index(drop=True)\n",
        "val_df = df.loc[val_ind].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ecfa279",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:45.071691Z",
          "iopub.status.busy": "2022-07-24T07:08:45.071428Z",
          "iopub.status.idle": "2022-07-24T07:08:45.620658Z",
          "shell.execute_reply": "2022-07-24T07:08:45.619935Z"
        },
        "papermill": {
          "duration": 0.6056,
          "end_time": "2022-07-24T07:08:45.623051",
          "exception": false,
          "start_time": "2022-07-24T07:08:45.017451",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "678b68a48697485bb1b24a47fe869793",
            "bbe15b7c76f5439fbf9fef1935273e93"
          ]
        },
        "id": "4ecfa279",
        "outputId": "abbec786-7f72-4f23-9437-a4da3b29438a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "678b68a48697485bb1b24a47fe869793",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/180 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbe15b7c76f5439fbf9fef1935273e93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def generate_triplet(df, mode='train'):\n",
        "  triplets = []\n",
        "  ids = df.id.unique()\n",
        "  random_drop = np.random.random(size=10000)>0.9\n",
        "  count = 0\n",
        "\n",
        "  for id, df_tmp in tqdm(df.groupby('id')):\n",
        "    df_tmp_markdown = df_tmp[df_tmp['cell_type']=='markdown']\n",
        "\n",
        "    df_tmp_code = df_tmp[df_tmp['cell_type']=='code']\n",
        "    df_tmp_code_rank = df_tmp_code['rank'].values\n",
        "    df_tmp_code_cell_id = df_tmp_code['cell_id'].values\n",
        "\n",
        "    for cell_id, rank in df_tmp_markdown[['cell_id', 'rank']].values:\n",
        "      labels = np.array([(r==(rank+1)) for r in df_tmp_code_rank]).astype('int')\n",
        "\n",
        "      for cid, label in zip(df_tmp_code_cell_id, labels):\n",
        "        count += 1\n",
        "        if label==1:\n",
        "          triplets.append( [cell_id, cid, label] )\n",
        "          # triplets.append( [cid, cell_id, label] )\n",
        "        elif mode == 'test':\n",
        "          triplets.append( [cell_id, cid, label] )\n",
        "          # triplets.append( [cid, cell_id, label] )\n",
        "        elif random_drop[count%10000]:\n",
        "          triplets.append( [cell_id, cid, label] )\n",
        "          # triplets.append( [cid, cell_id, label] )\n",
        "    \n",
        "  return triplets\n",
        "\n",
        "triplets = generate_triplet(train_df)\n",
        "val_triplets = generate_triplet(val_df, mode = 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cee1c136",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:45.727290Z",
          "iopub.status.busy": "2022-07-24T07:08:45.726824Z",
          "iopub.status.idle": "2022-07-24T07:08:45.739326Z",
          "shell.execute_reply": "2022-07-24T07:08:45.738682Z"
        },
        "papermill": {
          "duration": 0.066156,
          "end_time": "2022-07-24T07:08:45.741296",
          "exception": false,
          "start_time": "2022-07-24T07:08:45.675140",
          "status": "completed"
        },
        "tags": [],
        "id": "cee1c136",
        "outputId": "3e655780-fbb6-4e02-d9e4-4e301a61ea37"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cell_id</th>\n",
              "      <th>cell_type</th>\n",
              "      <th>source</th>\n",
              "      <th>rank</th>\n",
              "      <th>ancestor_id</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>pct_rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>051d049a469e47</td>\n",
              "      <td>d7e4aeec</td>\n",
              "      <td>code</td>\n",
              "      <td>install pyspark</td>\n",
              "      <td>1</td>\n",
              "      <td>6aff1937</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.010989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>051d049a469e47</td>\n",
              "      <td>aeb2a838</td>\n",
              "      <td>code</td>\n",
              "      <td>from pyspark import sparksession spark sparksession builder appname classification getorcreate</td>\n",
              "      <td>3</td>\n",
              "      <td>6aff1937</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.032967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>051d049a469e47</td>\n",
              "      <td>12c1a908</td>\n",
              "      <td>code</td>\n",
              "      <td>from itertools import chain from pyspark function import count mean when create_map regexp_extract</td>\n",
              "      <td>4</td>\n",
              "      <td>6aff1937</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.043956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>051d049a469e47</td>\n",
              "      <td>e7e68995</td>\n",
              "      <td>code</td>\n",
              "      <td>spark read input titanic train header true inferschema true spark read input titanic test header true inferschema true</td>\n",
              "      <td>6</td>\n",
              "      <td>6aff1937</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.065934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>051d049a469e47</td>\n",
              "      <td>320bedc7</td>\n",
              "      <td>code</td>\n",
              "      <td>printschema</td>\n",
              "      <td>8</td>\n",
              "      <td>6aff1937</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.087912</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               id   cell_id cell_type                                                                                                                  source rank ancestor_id  \\\n",
              "0  051d049a469e47  d7e4aeec      code                                                                                                         install pyspark    1    6aff1937   \n",
              "1  051d049a469e47  aeb2a838      code                          from pyspark import sparksession spark sparksession builder appname classification getorcreate    3    6aff1937   \n",
              "2  051d049a469e47  12c1a908      code                      from itertools import chain from pyspark function import count mean when create_map regexp_extract    4    6aff1937   \n",
              "3  051d049a469e47  e7e68995      code  spark read input titanic train header true inferschema true spark read input titanic test header true inferschema true    6    6aff1937   \n",
              "4  051d049a469e47  320bedc7      code                                                                                                             printschema    8    6aff1937   \n",
              "\n",
              "  parent_id  pct_rank  \n",
              "0       NaN  0.010989  \n",
              "1       NaN  0.032967  \n",
              "2       NaN  0.043956  \n",
              "3       NaN  0.065934  \n",
              "4       NaN  0.087912  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccd5d60e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:45.846664Z",
          "iopub.status.busy": "2022-07-24T07:08:45.845953Z",
          "iopub.status.idle": "2022-07-24T07:08:45.852728Z",
          "shell.execute_reply": "2022-07-24T07:08:45.852069Z"
        },
        "papermill": {
          "duration": 0.060941,
          "end_time": "2022-07-24T07:08:45.854340",
          "exception": false,
          "start_time": "2022-07-24T07:08:45.793399",
          "status": "completed"
        },
        "tags": [],
        "id": "ccd5d60e"
      },
      "outputs": [],
      "source": [
        "from bisect import bisect\n",
        "\n",
        "\n",
        "def count_inversions(a):\n",
        "    inversions = 0\n",
        "    sorted_so_far = []\n",
        "    for i, u in enumerate(a):\n",
        "        j = bisect(sorted_so_far, u)\n",
        "        inversions += i - j\n",
        "        sorted_so_far.insert(j, u)\n",
        "    return inversions\n",
        "\n",
        "\n",
        "def kendall_tau(ground_truth, predictions):\n",
        "    total_inversions = 0\n",
        "    total_2max = 0  # twice the maximum possible inversions across all instances\n",
        "    for gt, pred in zip(ground_truth, predictions):\n",
        "        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n",
        "        total_inversions += count_inversions(ranks)\n",
        "        n = len(gt)\n",
        "        total_2max += n * (n - 1)\n",
        "    return 1 - 4 * total_inversions / total_2max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f21ce49",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:45.962455Z",
          "iopub.status.busy": "2022-07-24T07:08:45.961755Z",
          "iopub.status.idle": "2022-07-24T07:08:48.028497Z",
          "shell.execute_reply": "2022-07-24T07:08:48.027727Z"
        },
        "papermill": {
          "duration": 2.123103,
          "end_time": "2022-07-24T07:08:48.030906",
          "exception": false,
          "start_time": "2022-07-24T07:08:45.907803",
          "status": "completed"
        },
        "tags": [],
        "id": "1f21ce49"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from transformers import AutoModelWithLMHead, AutoTokenizer, AutoModel\n",
        "\n",
        "MAX_LEN = 128\n",
        "\n",
        "    \n",
        "class MarkdownModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MarkdownModel, self).__init__()\n",
        "        self.distill_bert = AutoModel.from_pretrained(\"../input/mymodelpairbertsmallpretrained/models/checkpoint-18000\")\n",
        "        self.top = nn.Linear(512, 1)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, ids, mask):\n",
        "        x = self.distill_bert(ids, mask)[0]\n",
        "        x = self.dropout(x)\n",
        "        x = self.top(x[:, 0, :])\n",
        "        x = torch.sigmoid(x) \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3061dbc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:48.134233Z",
          "iopub.status.busy": "2022-07-24T07:08:48.133985Z",
          "iopub.status.idle": "2022-07-24T07:08:48.142091Z",
          "shell.execute_reply": "2022-07-24T07:08:48.141439Z"
        },
        "papermill": {
          "duration": 0.061457,
          "end_time": "2022-07-24T07:08:48.143815",
          "exception": false,
          "start_time": "2022-07-24T07:08:48.082358",
          "status": "completed"
        },
        "tags": [],
        "id": "b3061dbc"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "\n",
        "class MarkdownDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, df, max_len, mode='train'):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"../input/mymodelpairbertsmallpretrained/my_own_tokenizer\", do_lower_case=True)\n",
        "        self.mode=mode\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.df[index]\n",
        "\n",
        "        label = row[-1]\n",
        "\n",
        "        txt = dict_cellid_source[row[0]] + '[SEP]' + dict_cellid_source[row[1]]\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            txt,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding=\"max_length\",\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = torch.LongTensor(inputs['input_ids'])\n",
        "        mask = torch.LongTensor(inputs['attention_mask'])\n",
        "\n",
        "        return ids, mask, torch.FloatTensor([label])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b51fe02",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:48.247169Z",
          "iopub.status.busy": "2022-07-24T07:08:48.246917Z",
          "iopub.status.idle": "2022-07-24T07:08:48.252937Z",
          "shell.execute_reply": "2022-07-24T07:08:48.252254Z"
        },
        "papermill": {
          "duration": 0.059485,
          "end_time": "2022-07-24T07:08:48.254585",
          "exception": false,
          "start_time": "2022-07-24T07:08:48.195100",
          "status": "completed"
        },
        "tags": [],
        "id": "4b51fe02"
      },
      "outputs": [],
      "source": [
        "def adjust_lr(optimizer, epoch):\n",
        "    if epoch < 1:\n",
        "        lr = 5e-5\n",
        "    elif epoch < 2:\n",
        "        lr = 1e-3\n",
        "    elif epoch < 5:\n",
        "        lr = 1e-4\n",
        "    else:\n",
        "        lr = 1e-5\n",
        "\n",
        "    for p in optimizer.param_groups:\n",
        "        p['lr'] = lr\n",
        "    return lr\n",
        "    \n",
        "def get_optimizer(net):\n",
        "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=3e-4, betas=(0.9, 0.999), eps=1e-08)\n",
        "    return optimizer\n",
        "\n",
        "BS = 128\n",
        "NW = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49fd32c5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:48.358644Z",
          "iopub.status.busy": "2022-07-24T07:08:48.358372Z",
          "iopub.status.idle": "2022-07-24T07:08:48.366974Z",
          "shell.execute_reply": "2022-07-24T07:08:48.366264Z"
        },
        "papermill": {
          "duration": 0.062701,
          "end_time": "2022-07-24T07:08:48.368658",
          "exception": false,
          "start_time": "2022-07-24T07:08:48.305957",
          "status": "completed"
        },
        "tags": [],
        "id": "49fd32c5"
      },
      "outputs": [],
      "source": [
        "def read_data(data):\n",
        "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
        "\n",
        "def validate(model, val_loader, mode='train'):\n",
        "    model.eval()\n",
        "    \n",
        "    tbar = tqdm(val_loader, file=sys.stdout)\n",
        "    \n",
        "    preds = np.zeros(len(val_loader.dataset), dtype='float32')\n",
        "    labels = []\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, data in enumerate(tbar):\n",
        "            inputs, target = read_data(data)\n",
        "\n",
        "            pred = model(inputs[0], inputs[1]).detach().cpu().numpy().ravel()\n",
        "\n",
        "            preds[count:count+len(pred)] = pred\n",
        "            count += len(pred)\n",
        "            \n",
        "            if mode=='test':\n",
        "              labels.append(target.detach().cpu().numpy().ravel())\n",
        "    if mode=='test':\n",
        "      return preds\n",
        "    else:\n",
        "      return np.concatenate(labels), np.concatenate(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea7655e8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:48.472876Z",
          "iopub.status.busy": "2022-07-24T07:08:48.472406Z",
          "iopub.status.idle": "2022-07-24T07:08:48.537263Z",
          "shell.execute_reply": "2022-07-24T07:08:48.536549Z"
        },
        "papermill": {
          "duration": 0.118139,
          "end_time": "2022-07-24T07:08:48.539099",
          "exception": false,
          "start_time": "2022-07-24T07:08:48.420960",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "e9278dd4b9d0425783f0db7993948687"
          ]
        },
        "id": "ea7655e8",
        "outputId": "df7cdf1d-9a4c-4df7-f3f9-abc14546c544"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9278dd4b9d0425783f0db7993948687",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Test NBs:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "paths_test = list((data_dir / 'test').glob('*.json'))\n",
        "notebooks_test = [\n",
        "    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n",
        "]\n",
        "test_df = (\n",
        "    pd.concat(notebooks_test)\n",
        "    .set_index('id', append=True)\n",
        "    .swaplevel()\n",
        "    .sort_index(level='id', sort_remaining=False)\n",
        ").reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c548a5e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:48.645886Z",
          "iopub.status.busy": "2022-07-24T07:08:48.645637Z",
          "iopub.status.idle": "2022-07-24T07:08:48.735538Z",
          "shell.execute_reply": "2022-07-24T07:08:48.734871Z"
        },
        "papermill": {
          "duration": 0.144345,
          "end_time": "2022-07-24T07:08:48.737817",
          "exception": false,
          "start_time": "2022-07-24T07:08:48.593472",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "f26696c372974cafa4bddfb0188a9a0a"
          ]
        },
        "id": "2c548a5e",
        "outputId": "289042bb-ee85-40e2-9b18-427e42630b0f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f26696c372974cafa4bddfb0188a9a0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_df.source = test_df.source.apply(preprocess_text)\n",
        "dict_cellid_source = dict(zip(test_df['cell_id'].values, test_df['source'].values))\n",
        "test_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\n",
        "test_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=False)\n",
        "test_triplets = generate_triplet(test_df, mode = 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf580a3a",
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:48.847562Z",
          "iopub.status.busy": "2022-07-24T07:08:48.847295Z",
          "iopub.status.idle": "2022-07-24T07:08:49.263220Z",
          "shell.execute_reply": "2022-07-24T07:08:49.262551Z"
        },
        "papermill": {
          "duration": 0.473968,
          "end_time": "2022-07-24T07:08:49.266330",
          "exception": false,
          "start_time": "2022-07-24T07:08:48.792362",
          "status": "completed"
        },
        "tags": [],
        "id": "bf580a3a",
        "outputId": "603d9396-091f-4a95-f37e-2c4a238af5a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(999,\n",
              " (tensor([  101, 25169,  2951,  4094,  2951,  4162,   102, 12324, 16371,  8737,\n",
              "           2100,  7399, 11208, 12324, 25462,  2951,  6364, 12324, 13523, 24759,\n",
              "           4140, 29521,  1052, 22571, 10994,  2013, 15315, 19738,  6826, 22511,\n",
              "          12324,  2013, 15315, 19738,  6826, 17463,  3217,  9623,  7741, 12324,\n",
              "           4781,  9289,  2121,  2013, 15315, 19738,  6826, 17463,  3217,  9623,\n",
              "           7741, 12324,  4094,  2013, 15315, 19738,  6826, 17727, 10421, 12324,\n",
              "           3722,  5714, 18780,  2121, 12324, 16101, 18442,  5371, 18442,  3328,\n",
              "          10556, 24679,  7953,  5371, 18442,  5371, 18442,  6140,  4130,  3693,\n",
              "          16101, 18442,  5371, 18442,   102,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0]),\n",
              "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "  tensor([0.])))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df[\"pct_rank\"] = 0\n",
        "test_ds = MarkdownDataset(test_triplets, max_len=MAX_LEN)\n",
        "# batch_size : 몇 개의 샘플로 가중치를 갱신할 것인지 설정\n",
        "# num_workers : 코어 할당\n",
        "# pin_memory : dataloader의 리턴값을 gpu 를 쓰는 텐서로 변환\n",
        "test_loader = DataLoader(test_ds, batch_size=BS * 4, shuffle=False, num_workers=NW, pin_memory=False, drop_last=False)\n",
        "\n",
        "import gc \n",
        "gc.collect()\n",
        "len(test_ds), test_ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52ce6047",
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:49.375199Z",
          "iopub.status.busy": "2022-07-24T07:08:49.374923Z",
          "iopub.status.idle": "2022-07-24T07:08:57.383893Z",
          "shell.execute_reply": "2022-07-24T07:08:57.383093Z"
        },
        "papermill": {
          "duration": 8.065002,
          "end_time": "2022-07-24T07:08:57.385929",
          "exception": false,
          "start_time": "2022-07-24T07:08:49.320927",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "87e0edaf0f4d4ab6a7e1727429e42ca7"
          ]
        },
        "id": "52ce6047",
        "outputId": "5cef92f3-538b-40d7-a145-f858b5eb7bd1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ../input/mymodelpairbertsmallpretrained/models/checkpoint-18000 were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at ../input/mymodelpairbertsmallpretrained/models/checkpoint-18000 and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87e0edaf0f4d4ab6a7e1727429e42ca7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "# 따로 만든 모델 로드해서 확인\n",
        "import sys \n",
        "\n",
        "model = MarkdownModel()\n",
        "model = model.cuda()\n",
        "# load_state_dict : 역직렬화된 state_dict를 사용, 모델의 매개변수들을 불러온다.\n",
        "# state_dict : 각 체층을 매개변수 Tensor로 매핑한 Python 사전(dict) 객체\n",
        "model.load_state_dict(torch.load('../input/mymodelbertsmallpretrained120000/my_own_model.bin'))\n",
        "y_test = validate(model, test_loader, mode='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42c29d19",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:57.502508Z",
          "iopub.status.busy": "2022-07-24T07:08:57.501822Z",
          "iopub.status.idle": "2022-07-24T07:08:57.957404Z",
          "shell.execute_reply": "2022-07-24T07:08:57.956622Z"
        },
        "papermill": {
          "duration": 0.516313,
          "end_time": "2022-07-24T07:08:57.960461",
          "exception": false,
          "start_time": "2022-07-24T07:08:57.444148",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "5e92056c98784ac691d45c656b224189"
          ]
        },
        "id": "42c29d19",
        "outputId": "c13c4e17-9b60-429f-8bf5-bbfe9975ee36"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e92056c98784ac691d45c656b224189",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "preds_copy = y_test\n",
        "pred_vals = []\n",
        "count = 0\n",
        "for id, df_tmp in tqdm(test_df.groupby('id')):\n",
        "  df_tmp_mark = df_tmp[df_tmp['cell_type']=='markdown']\n",
        "  df_tmp_code = df_tmp[df_tmp['cell_type']!='markdown']\n",
        "  df_tmp_code_rank = df_tmp_code['rank'].rank().values\n",
        "  N_code = len(df_tmp_code_rank)\n",
        "  N_mark = len(df_tmp_mark)\n",
        "\n",
        "  preds_tmp = preds_copy[count:count+N_mark * N_code]\n",
        "\n",
        "  count += N_mark * N_code\n",
        "\n",
        "  for i in range(N_mark):\n",
        "    pred = preds_tmp[i*N_code:i*N_code+N_code] \n",
        "\n",
        "    softmax = np.exp((pred-np.mean(pred)) *20)/np.sum(np.exp((pred-np.mean(pred)) *20)) \n",
        "\n",
        "    rank = np.sum(softmax * df_tmp_code_rank)\n",
        "    pred_vals.append(rank)\n",
        "\n",
        "del model\n",
        "del test_triplets[:]\n",
        "del dict_cellid_source\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f0f12d3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:58.079465Z",
          "iopub.status.busy": "2022-07-24T07:08:58.078766Z",
          "iopub.status.idle": "2022-07-24T07:08:58.091823Z",
          "shell.execute_reply": "2022-07-24T07:08:58.091048Z"
        },
        "papermill": {
          "duration": 0.074768,
          "end_time": "2022-07-24T07:08:58.093767",
          "exception": false,
          "start_time": "2022-07-24T07:08:58.018999",
          "status": "completed"
        },
        "tags": [],
        "id": "8f0f12d3"
      },
      "outputs": [],
      "source": [
        "# 정렬하고 묶어서 붙이기 \n",
        "test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = pred_vals\n",
        "sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
        "sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
        "sub_df.to_csv(\"submission_2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96c464b5",
      "metadata": {
        "papermill": {
          "duration": 0.057614,
          "end_time": "2022-07-24T07:08:58.212838",
          "exception": false,
          "start_time": "2022-07-24T07:08:58.155224",
          "status": "completed"
        },
        "tags": [],
        "id": "96c464b5"
      },
      "source": [
        "_____\n",
        "\n",
        "## Rank Ensemble\n",
        "\n",
        "###### (finally)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b10368e",
      "metadata": {
        "papermill": {
          "duration": 0.057004,
          "end_time": "2022-07-24T07:08:58.327639",
          "exception": false,
          "start_time": "2022-07-24T07:08:58.270635",
          "status": "completed"
        },
        "tags": [],
        "id": "1b10368e"
      },
      "source": [
        "And now for the moment we have all been waiting for: **Ensemling rank based submissions.**\n",
        "\n",
        "But how are we going to do this?\n",
        "\n",
        "- Let's say that we have two different submissions: \"submission_1.csv\", \"submission_2.csv\". Each containing a list of sorted strings per row.\n",
        "- We would like to create a new submission such that each row contains a sorted list that is an aggregation of the sorted list in the same row of both submissions.\n",
        "- To do this, we simply ensemble the indices. The index is nothing but a rank of a particular string. From the highest likelyhood of the string being in it's expected package to the lowest.\n",
        "- Then sort the strings by their ensembled index."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "090ac3e1",
      "metadata": {
        "papermill": {
          "duration": 0.057464,
          "end_time": "2022-07-24T07:08:58.443792",
          "exception": false,
          "start_time": "2022-07-24T07:08:58.386328",
          "status": "completed"
        },
        "tags": [],
        "id": "090ac3e1"
      },
      "source": [
        "**Reading the submissions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05327a18",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:58.561094Z",
          "iopub.status.busy": "2022-07-24T07:08:58.560843Z",
          "iopub.status.idle": "2022-07-24T07:08:58.568533Z",
          "shell.execute_reply": "2022-07-24T07:08:58.567774Z"
        },
        "papermill": {
          "duration": 0.068713,
          "end_time": "2022-07-24T07:08:58.570299",
          "exception": false,
          "start_time": "2022-07-24T07:08:58.501586",
          "status": "completed"
        },
        "tags": [],
        "id": "05327a18"
      },
      "outputs": [],
      "source": [
        "df_1 = pd.read_csv('submission_2.csv')\n",
        "df_2 = pd.read_csv('submission_1.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ac09e5a",
      "metadata": {
        "papermill": {
          "duration": 0.058503,
          "end_time": "2022-07-24T07:08:58.688031",
          "exception": false,
          "start_time": "2022-07-24T07:08:58.629528",
          "status": "completed"
        },
        "tags": [],
        "id": "4ac09e5a"
      },
      "source": [
        "**Averaging the indices and sorting the resulting submission by the aggregated ensembled indices**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43d0e5ff",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:58.804304Z",
          "iopub.status.busy": "2022-07-24T07:08:58.803515Z",
          "iopub.status.idle": "2022-07-24T07:08:58.812974Z",
          "shell.execute_reply": "2022-07-24T07:08:58.812298Z"
        },
        "papermill": {
          "duration": 0.069018,
          "end_time": "2022-07-24T07:08:58.814804",
          "exception": false,
          "start_time": "2022-07-24T07:08:58.745786",
          "status": "completed"
        },
        "tags": [],
        "id": "43d0e5ff"
      },
      "outputs": [],
      "source": [
        "\n",
        "new_samples = []\n",
        "for sample_idx in range(len(df_1)):\n",
        "    sample_1 = {k: v for v, k in enumerate(df_1.iloc[sample_idx]['cell_order'].split(' '))}\n",
        "    sample_2 = {k: v for v, k in enumerate(df_2.iloc[sample_idx]['cell_order'].split(' '))}\n",
        "    for key in sample_1: sample_1[key] = ( (sample_1[key] * 0.251) + (sample_2[key] * 0.749) )\n",
        "    new_samples.append(' '.join([i[0] for i in list(sorted(sample_1.items(), key=lambda x:x[1]))]))\n",
        "df_1['cell_order'] = new_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f8c3a9b",
      "metadata": {
        "papermill": {
          "duration": 0.056841,
          "end_time": "2022-07-24T07:08:58.929073",
          "exception": false,
          "start_time": "2022-07-24T07:08:58.872232",
          "status": "completed"
        },
        "tags": [],
        "id": "4f8c3a9b"
      },
      "source": [
        "**Saving as output so we can submit**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c11d10a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-24T07:08:59.046222Z",
          "iopub.status.busy": "2022-07-24T07:08:59.045969Z",
          "iopub.status.idle": "2022-07-24T07:08:59.055979Z",
          "shell.execute_reply": "2022-07-24T07:08:59.055209Z"
        },
        "papermill": {
          "duration": 0.071443,
          "end_time": "2022-07-24T07:08:59.058037",
          "exception": false,
          "start_time": "2022-07-24T07:08:58.986594",
          "status": "completed"
        },
        "tags": [],
        "id": "2c11d10a",
        "outputId": "f5d11887-8c78-4e98-d0e7-3d7c47f7d5df"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cell_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0009d135ece78d</td>\n",
              "      <td>0a226b6a ddfd239c 8cb8d28a c6cd22db 1372ae9b e25aa9bd 90ed07ab ba55e576 f9893819 7f388a41 2843a25a 39e937ec 06dbf8cf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0010483c12ba9b</td>\n",
              "      <td>7f270e34 54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0010a919d60e4f</td>\n",
              "      <td>23607d04 b7578789 aafc3d23 bbff12d4 80e077ec b190ebb4 584f6568 d3f5c397 8ce62db4 89b1fdd2 ed415c3c 322850af 7f53de45...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0028856e09c5b7</td>\n",
              "      <td>eb293dfc 012c9d02 d22526d1 3ae7ece3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               id                                                                                                               cell_order\n",
              "0  0009d135ece78d     0a226b6a ddfd239c 8cb8d28a c6cd22db 1372ae9b e25aa9bd 90ed07ab ba55e576 f9893819 7f388a41 2843a25a 39e937ec 06dbf8cf\n",
              "1  0010483c12ba9b                                7f270e34 54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d\n",
              "2  0010a919d60e4f  23607d04 b7578789 aafc3d23 bbff12d4 80e077ec b190ebb4 584f6568 d3f5c397 8ce62db4 89b1fdd2 ed415c3c 322850af 7f53de45...\n",
              "3  0028856e09c5b7                                                                                      eb293dfc 012c9d02 d22526d1 3ae7ece3"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_1.to_csv('submission.csv', index = False)\n",
        "df_1"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 90.417455,
      "end_time": "2022-07-24T07:09:02.872018",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-07-24T07:07:32.454563",
      "version": "2.3.4"
    },
    "colab": {
      "name": "ai4code-codebert-pairwise-score.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}